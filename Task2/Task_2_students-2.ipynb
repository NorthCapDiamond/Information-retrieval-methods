{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_ST0GfO97y"
      },
      "source": [
        "# Информационный поиск\n",
        "\n",
        "Скачиваем классический набор данных -- набор текстов об аэронавтике CRANFIELD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHflLH2APAHK",
        "outputId": "e6d1427c-a5bd-4b63-ae6d-ca4383ca74d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cran.all.1400\n",
            "cran.qry\n",
            "cranqrel\n",
            "cranqrel.readme\n"
          ]
        }
      ],
      "source": [
        "! wget -q http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n",
        "! tar -xvf cran.tar.gz\n",
        "! rm cran.tar.gz*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYuND83cPR5D"
      },
      "source": [
        "Берём только сами запросы (это будут наши документы)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6owW-L7zhJws",
        "outputId": "c904b964-07cc-4345-e563-15a6d7a95c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what similarity laws must be obeyed when constructing aeroelastic models\r\n",
            "of heated high speed aircraft .\r\n",
            "what are the structural and aeroelastic problems associated with flight\r\n"
          ]
        }
      ],
      "source": [
        "! grep -v \"^\\.\" cran.qry > just.qry\n",
        "! head -3 just.qry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZbUb6FmQxr1"
      },
      "source": [
        "Объединяем многострочные в один"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBaV3xeQiUam",
        "outputId": "e50a6e05-1fa6-41b2-a5a0-4c755ecb1f87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . ',\n",
              " 'what are the structural and aeroelastic problems associated with flight of high speed aircraft . ']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "raw_query_data = [line.strip() for line in open(\"just.qry\", \"r\").readlines()]\n",
        "query_data = [\"\"]\n",
        "\n",
        "for query_part in raw_query_data:\n",
        "  query_data[-1] += query_part + \" \"\n",
        "  if query_part.endswith(\".\"):\n",
        "    query_data.append(\"\")\n",
        "\n",
        "query_data[:2] #Выведем пару документов для примера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFq_6lBki3S"
      },
      "source": [
        "### Составим запросы к нашим документам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "h3sgHjWkjjR1"
      },
      "outputs": [],
      "source": [
        "QUERIES = ['mixing problem']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQMdH0HSkoJg"
      },
      "source": [
        "## Boolean retrieval\n",
        "Представим каждый документ как \"битовую маску\": вектор размером со словарь, в котором на каждой позиции единица, если в документе есть соответсвующий терм, и ноль, если терма нет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lhrI18rZSLLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21b34c0-a3b3-4b0e-8c25-4c49b9da92b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not build wheels for scikit-learn, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# в разных версиях ответы могут отличаться, поэтому важно иметь одну и ту же\n",
        "! pip install -q scikit-learn==0.22.2.post1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbTOdsHIknD0",
        "outputId": "afeab484-4e27-497c-e9fc-a972157cf11d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "encoder = CountVectorizer(binary=True)\n",
        "encoded_data = encoder.fit_transform(query_data)\n",
        "encoded_queries = encoder.transform(QUERIES)\n",
        "list(encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUdwKDKSTjdD"
      },
      "source": [
        "Посмотрим на представление первого предложения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXEmXErylJdX",
        "outputId": "d0ecb8b0-f317-49c9-e9a9-4136d8499dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'similarity',\n",
              " 'laws',\n",
              " 'must',\n",
              " 'be',\n",
              " 'obeyed',\n",
              " 'when',\n",
              " 'constructing',\n",
              " 'aeroelastic',\n",
              " 'models',\n",
              " 'of',\n",
              " 'heated',\n",
              " 'high',\n",
              " 'speed',\n",
              " 'aircraft']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "id2term = {idx: term for term, idx in encoder.vocabulary_.items()}\n",
        "non_zero_values_ids = encoded_data[0].nonzero()[1]\n",
        "\n",
        "terms = [id2term[idx] for idx in non_zero_values_ids]\n",
        "terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wdS9XiVwb2"
      },
      "source": [
        "Всё так.\n",
        "\n",
        "## Задание 0\n",
        "\n",
        "Теперь для каждого из данных запросов `QUERIES` найдём ближайший для него документ из `query_data` по сходству Жаккара. Есть более эффективные способы это сделать, но вам требуется реализовать расстояние Жаккара и далее применить его к нашим данным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "u31WuBYAUWt2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def jaccard_sim(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Сходство или коэффициент Жаккара: отношение мощности пересечения\n",
        "    к мощности объединения\n",
        "  \"\"\"\n",
        "  intersection = np.logical_and(vector_a, vector_b).sum()\n",
        "  union = np.logical_or(vector_a, vector_b).sum()\n",
        "  return intersection / union\n",
        "\n",
        "#Проверка, что функция работает правильно\n",
        "assert jaccard_sim(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1])) == 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmxAPCceo7FW"
      },
      "source": [
        "Здесь документы представлены так же, как строки в матрице термов-документов. Каждая ячейка вектора отвечает за наличие/отсутствие конкретного элемента (например, слова-терма, когда у нас в словаре всего 5 слов). В первом случае их три, во втором — четыре. Объединение — все пять возможных элементов. Пересечение — два. Отсюда и 0.4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfQksWrOR1G"
      },
      "source": [
        "## Задание 1\n",
        "Теперь с помощью кода ниже вычислите для каждого запроса самые близкие документы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4okpFpA6OAQs",
        "outputId": "043e02ed-c9dc-4fdd-8fdc-1ba3979cb50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: mixing problem\n",
            "FOUND:\n",
            "    59\t0.10\tis there any simple,  but practical,  method for numerical integration of the mixing problem (i.e. the blasius problem with three-point boundary conditions) . \n",
            "    172\t0.09\tsolution of the blasius problem with three-point boundary conditions . \n",
            "    196\t0.07\tthe problem of similarity for representative investigation of aeroelastic effects in a flow with the absence of heating effects . \n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(encoded_queries):\n",
        "  # приводим к нужному типу\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in encoded_data]\n",
        "  # вычисляем коэфф. Жаккара\n",
        "  id2doc2similarity = [(doc_id, doc, jaccard_sim(query, doc)) for doc_id, doc in enumerate(docs)]\n",
        "  # сортируем по нему\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "  # выводим по 3 наиболее близких документа для каждого запроса\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Fh8RdvOrAD"
      },
      "source": [
        "Видим, что кое-где просачиваются  тексты, которых с запросами объединяют малозначительные термы, но при этом коэффициент Жаккара -- наша функция ранжирования! -- высок.\n",
        "\n",
        "# VSM\n",
        "\n",
        "Попробуем теперь сделать то же, но с tf-idf и косинусным расстоянием. Мы сделаем всё опять \"руками\", но \"в реальной жизни\" лучше использоватьесть эффективные реализации cosine distance, например, из библиотеки scipy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmpKMI08E2iO",
        "outputId": "1dcbf36a-b266-42e1-c484-c74107418489"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Совет: обязательно разберитесь с тем, какие возможности\n",
        "# предоставляет tf-idf vectorizer, какие параметры за что отвечают\n",
        "\n",
        "tfidf_encoder = TfidfVectorizer()\n",
        "tfidf_encoded_data = tfidf_encoder.fit_transform(query_data)\n",
        "tfidf_encoded_queries = tfidf_encoder.transform(QUERIES)\n",
        "\n",
        "list(tfidf_encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHTzIjfNRHj2"
      },
      "source": [
        "## Задание 2\n",
        "Реализовать косинусное расстояние"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "UCfgR6xEPeDn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_distance(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Косинусное расстояние: единица минус отношение скалярного произведения\n",
        "    на произведение L2-норм (подсказка: в numpy такие нормы есть)\n",
        "  \"\"\"\n",
        "  dot_product = np.dot(vector_a, vector_b)\n",
        "  norm_a = np.linalg.norm(vector_a)\n",
        "  norm_b = np.linalg.norm(vector_b)\n",
        "  return 1 - (dot_product / (norm_a * norm_b))\n",
        "\n",
        "#Проверка, что функция работает правильно\n",
        "assert cosine_distance(np.array([1, 0, 1, 1, 1]), np.array([0, 0, 1, 0, 0])) == 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHsaHoORlEC"
      },
      "source": [
        "\n",
        "Теперь вычислим ближайшие по косинусному расстоянию между векторными представлениями документов и запросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIZJRBKQQR1G",
        "outputId": "233dd146-e44e-41b2-e4f1-cb0efaa41951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: mixing problem\n",
            "FOUND:\n",
            "    59\t0.56\tis there any simple,  but practical,  method for numerical integration of the mixing problem (i.e. the blasius problem with three-point boundary conditions) . \n",
            "    16\t0.79\tcan the three-dimensional problem of a transverse potential flow about a body of revolution be reduced to a two-dimensional problem . \n",
            "    172\t0.83\tsolution of the blasius problem with three-point boundary conditions . \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-3f00d22a22be>:11: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  return 1 - (dot_product / (norm_a * norm_b))\n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(tfidf_encoded_queries):\n",
        "\n",
        "  # приводим к нужному типу\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in tfidf_encoded_data]\n",
        "  # Косинусное расстояние\n",
        "  id2doc2similarity = [(doc_id, doc, cosine_distance(query, doc)) \\\n",
        "                       for doc_id, doc in enumerate(docs)]\n",
        "  # сортируем по нему\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=False)\n",
        "\n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}