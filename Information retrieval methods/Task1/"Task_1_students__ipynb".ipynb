{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUuyLVDZ4s8r"
      },
      "source": [
        "## ЗАДАНИЕ ДЛЯ ПРОГРАММИРУЮЩИХ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJ5Q6w2IFHA"
      },
      "source": [
        "**Ссылка**, на источник текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64uxt-07IEec"
      },
      "source": [
        "#DATA_URL = \"http://az.lib.ru/t/tolstoj_a_k/text_0180.shtml\" # Train Data. Comments are made for this dataset\n",
        "DATA_URL = \"http://az.lib.ru/g/gogolx_n_w/text_0050.shtml\" # My test data"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwrBkeLnHuA1"
      },
      "source": [
        "Устанавливаем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Fr5swwYfz5"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!pip -q install rnnmorph"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxMKqhPH1Dk"
      },
      "source": [
        "Создаём объект морфологического анализатора `RNNMorph`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24zMUhvi99AV"
      },
      "source": [
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59q1L9p0H9K9"
      },
      "source": [
        "Скачиваем текст, по которому будет дано задание, с помощью `urllib`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uW0fw_h-Pft"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(DATA_URL)\n",
        "raw_text = resource.read().decode(resource.headers.get_content_charset()) #Текс с html тегами"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "-hSPOjDo4sdh",
        "outputId": "1f99053f-fa10-4950-896b-c83c6093dfb6"
      },
      "source": [
        "raw_text[:200]"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<html>\\r\\n<head>\\r\\n<title>Lib.ru/Классика: Гоголь Николай Васильевич. Вий</title>\\r\\n</head>\\r\\n\\r\\n<body>\\r\\n\\r\\n\\r\\n<center>\\r\\n\\r\\n<h2><a href=/g/gogolx_n_w/>Гоголь Николай Васильевич</a><br>\\r\\nВий</h2>\\r\\n\\r\\n<!------- П'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZiLHQNSITAt"
      },
      "source": [
        "Как видно, текст содержит html теги, от которых нужно избавиться. Выбрасываем из текста HTML-теги с помощью библиотеки Beatiful soap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We4LkyUMPfuq"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(raw_text, features=\"html.parser\")\n",
        "\n",
        "# kill all script and style elements\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()    # rip it out\n",
        "\n",
        "# get text\n",
        "cleaned_text = soup.get_text()"
      ],
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "lOD8PJnG4rbl",
        "outputId": "0ea87465-0f70-4000-dbdb-560ef79424d2"
      },
      "source": [
        "cleaned_text[:200]"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nLib.ru/Классика: Гоголь Николай Васильевич. Вий\\n\\n\\n\\nГоголь Николай Васильевич\\r\\nВий\\n\\n\\nLib.ru/Классика:\\n\\r\\n\\n\\n[Регистрация]\\n \\n\\r\\n\\r\\n\\r\\n[Найти] \\r\\n[Рейтинги]\\r\\n[Обсуждения]\\r\\n[Новинки]\\r\\n[Обзоры]\\r\\n[Помощь]\\r\\n\\r\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14fYYb5hIpnY"
      },
      "source": [
        "С помощью библиотеки [NLTK](https://nltk.org/) разбиваем текст на предложения и токены."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "hRNu7jPvN6G_",
        "outputId": "981d3de9-9688-48a9-8fed-a33284c8d4e0"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(cleaned_text)]\n",
        "\"A total of %d 'sentences'\" % len(tokenized_sentences)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A total of 934 'sentences'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRU4KEBAIyYT"
      },
      "source": [
        "## Задание 1\n",
        "С помощью метода `str.isalpha` из стандартной библиотеки Python модифицируйте нижеследующий код так, чтобы в predictions остались только буквенные токены."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U5HH2CDPVUM",
        "outputId": "55e69004-201f-4e2f-e875-439f2fbe35ef"
      },
      "source": [
        "from tqdm import tqdm\n",
        "predictions = [[pred.normal_form for pred in sent]\n",
        "               for sent in tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\") ]\n",
        "for i, el in enumerate(predictions):\n",
        "  predictions[i] = (list(filter(lambda sentencess : sentencess.isalpha(), el)))"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 9s 488ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sentences: 100%|██████████| 934/934 [00:00<00:00, 129332.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHGDhxhNJtTz"
      },
      "source": [
        "Проверьте себя. Должны получиться следующие значения:\n",
        "\n",
        "*   Предложений: 577 (возможны расхождения в несколько предложений)\n",
        "*   Токенов: примерно 8621 (возможны расхождения в некоторое количество токенов)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwK_qRbw6sac",
        "outputId": "6671c056-f339-4818-dd85-216622c0455c"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "934"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5jL4sWyKUnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962f8276-ca4f-44d2-edfb-61d03e377669"
      },
      "source": [
        "non_uniq_tokens = [word for sentence in predictions for word in sentence]\n",
        "len(non_uniq_tokens)\n"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11732"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg2e-1hAKiT3"
      },
      "source": [
        "Для продолжения работы над заданием числа должны быть близки к указанным"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mci9Nd5hKuJP"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Используя `non_uniq_tokens`, стоп-слова для русского языка из библиотеки nltk (`nltk.corpus.stopwords`) и `nltk.FreqDist`, вычислите, **какую долю среди 100 самых частотных** токенов в произведении занимают токены, **не относящиеся** к стоп словам.\n",
        "\n",
        "**Например**, если среди 100 самых частотных слов встречается 25 слов, входящих в стоп лист, значит не входят в стоп лист 75 слов, и их доля составит 0.75.\n",
        "\n",
        "**Не бойтесь использовать документацию NLTK и тьюториалы.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHbtLqkLKfZC",
        "outputId": "59e5ec32-c0fb-4779-c183-28dfa6f154d0"
      },
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from functools import reduce\n",
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = set(stopwords.words(\"russian\"))\n",
        "print(stopwords.words(\"russian\")[:5]) #Пример стоп слов\n",
        "\n",
        "n_amount_of_most_frequent = 50\n",
        "\n",
        "predictions_flatten = reduce(lambda x, y : x+y, predictions)\n",
        "freq_dist = FreqDist(w.lower() for w in predictions_flatten).items()\n",
        "all_words = FreqDist(w.lower() for w in predictions_flatten).most_common(n_amount_of_most_frequent)\n",
        "bad_words = FreqDist(w.lower() for w in predictions_flatten if w in STOPWORDS).items()\n",
        "\n",
        "all_words_set = []\n",
        "all_words_amount = 0\n",
        "bad_words_set = []\n",
        "bad_words_amount = 0\n",
        "\n",
        "for k, v in all_words:\n",
        "  all_words_set.append(k)\n",
        "  all_words_amount+=v\n",
        "for k, v in bad_words:\n",
        "  bad_words_set.append(k)\n",
        "  bad_words_amount+=v\n",
        "\n",
        "all_words_set = set(all_words_set)\n",
        "bad_words_set = set(bad_words_set)\n",
        "\n",
        "print(len(all_words_set - bad_words_set)/ len(all_words_set))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что']\n",
            "0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdbB95YwtSl"
      },
      "source": [
        "Проверьте себя: должно получиться 0.49 (допустимо небольшое расхождение)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HChyAdk2Ovx1"
      },
      "source": [
        "## Задание 3\n",
        "Вычислите, сколько токенов встречается в тексте **строго больше** 50 раз."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amount_of_tokens = 0\n",
        "for k, v in freq_dist:\n",
        "  if v > 50:\n",
        "    amount_of_tokens+=1\n",
        "amount_of_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX3SVK6NQSMx",
        "outputId": "83742517-f54e-4758-e5b4-3da2fda0af48"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6HZ2w3yxJEh"
      },
      "source": [
        "Проверьте себя: должно получиться значение 22 (возможно небольшое расхождение)\n"
      ]
    }
  ]
}